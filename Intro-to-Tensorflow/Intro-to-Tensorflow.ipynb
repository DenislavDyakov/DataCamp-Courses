{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a picture size converter in Python for use in documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "size = 256, 256\n",
    "\n",
    "im = Image.open(\"viber image.jpg\")\n",
    "im.thumbnail(size, Image.ANTIALIAS)\n",
    "im.save(\"viber_thumb.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the modules we will use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tensorflow import divide\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-1.0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.multiply(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.backprop.GradientTape at 0x7f603c054150>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "g = tape.gradient(y, x)\n",
    "print(g.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = tf.random.uniform([2, 2], maxval = 255, dtype = \"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[249, 213],\n",
       "       [128,  20]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = tf.reshape(gray, [2*2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int32, numpy=\n",
       "array([[249],\n",
       "       [213],\n",
       "       [128],\n",
       "       [ 20]], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n",
      "2.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(x0):\n",
    "    # Define x as a variable with an initial value of x0\n",
    "    x = tf.Variable(x0)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "        y = tf.multiply(x, x)\n",
    "    # Return the gradient of y with respect to x\n",
    "    return tape.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = np.array([[1],[0],[-1]], dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [-1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = np.array([[1., 0., 1.],\n",
    "       [1., 1., 0.],\n",
    "       [1., 0., 1.]], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Reshape model from a 1x3 to a 3x1 tensor\n",
    "model = tf.reshape(model, (1*3, 1))\n",
    "\n",
    "# Multiply letter by model\n",
    "output = tf.matmul(letter, model)\n",
    "\n",
    "# Sum over output and print prediction using the numpy method\n",
    "prediction = tf.reduce_sum(output)\n",
    "print(prediction.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_array = np.array(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = np.array(housing[\"price\"], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221900., 538000., 180000., ..., 402101., 400000., 325000.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront = np.array(housing[\"waterfront\"], np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterfront"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing but with tensorflow insted of numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = tf.cast(housing[\"price\"], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(21613,), dtype=float32, numpy=\n",
       "array([221900., 538000., 180000., ..., 402101., 400000., 325000.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront = tf.cast(housing[\"waterfront\"], tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(21613,), dtype=bool, numpy=array([False, False, False, ..., False, False, False])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        221900.0\n",
      "1        538000.0\n",
      "2        180000.0\n",
      "3        604000.0\n",
      "4        510000.0\n",
      "           ...   \n",
      "21608    360000.0\n",
      "21609    400000.0\n",
      "21610    402101.0\n",
      "21611    400000.0\n",
      "21612    325000.0\n",
      "Name: price, Length: 21613, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assign the path to a string variable named data_path\n",
    "data_path = 'kc_house_data.csv'\n",
    "\n",
    "# Load the dataset as a dataframe named housing\n",
    "housing = pd.read_csv(data_path)\n",
    "\n",
    "# Print the price column of housing\n",
    "print(housing[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play around with loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221900., 538000., 180000., ..., 402101., 400000., 325000.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for elem in price:\n",
    "    predict = elem - (elem * random.uniform(0.001, 0.2))\n",
    "    predictions.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.cast(predictions, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(21613,), dtype=float32, numpy=\n",
       "array([180739.45, 516416.2 , 146969.75, ..., 325173.06, 392968.3 ,\n",
       "       315491.5 ], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5756883500.0\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean squared error (mse)\n",
    "loss = keras.losses.mse(price, predictions)\n",
    "\n",
    "# Print the mean squared error (mse)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54314.434\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean absolute error (mae)\n",
    "loss = keras.losses.mae(price, predictions)\n",
    "\n",
    "# Print the mean squared error (mse)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540088.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = tf.Variable(1.0, tf.float32)\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features):\n",
    "    return scalar * features\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features, targets):\n",
    "    # Compute the predicted values\n",
    "    predictions = model(scalar, features)\n",
    "    \n",
    "    # Return the mean absolute error loss\n",
    "    return keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar, price, waterfront).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = np.array(housing[\"price\"], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = np.array(housing[\"sqft_living\"], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = tf.Variable(0.1, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = tf.Variable(0.1, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(intercept, slope, features = size):\n",
    "    return intercept + slope * features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(intercept, slope, targets = price, features = size):\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(426196570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426193780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426191100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426188400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426185700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426182930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426180280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426177500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426174800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426172120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426169340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426166600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426163860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426161180000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426158520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426155840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426153050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426150360000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426147680000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426144900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426142200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426139400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426136700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426133980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426131230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426128500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426125820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426123130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426120450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426117730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426114970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426112250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426109530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426106780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426104060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426101370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426098600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426095970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426093200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426090430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426087780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426085100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426082300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426079550000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426076900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426074100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426071430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426068740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426066020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426063330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426060580000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426057860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426055100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426052400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426049670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426046980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426044230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426041570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426038900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426036100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426033300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426030700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426027940000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426025250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426022470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426019750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426017060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426014380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426011600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426008970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426006200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426003500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(426000700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425998020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425995270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425992520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425989900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425987200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425984430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425981700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425978950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425976270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425973600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425970830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425968140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425965400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425962670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425959980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425957260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425954500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425951900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425949070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425946380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425943700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425940900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425938220000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425935540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425932750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425930060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425927340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425924720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425921940000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425919250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425916470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425913780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425911000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425908300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425905620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425902870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425900180000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425897430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425894700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425892000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425889230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425886550000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425883830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425881200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425878450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425875730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425872950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425870200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425867480000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425864900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425862100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425859320000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425856660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425853900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425851300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425848540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425845880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425843130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425840350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425837630000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425834870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425832150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425829430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425826750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425824060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425821370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425818600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425815870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425813100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425810460000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425807770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425805000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425802330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425799580000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425796830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425794100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425791420000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425788670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425786000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425783260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425780540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425777860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425775170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425772450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425769700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425766980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425764260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425761470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425758800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425756030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425753380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425750700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425748000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425745250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425742530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425739800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425737130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425734370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425731650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425728930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425726250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425723500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425720800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425718050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425715370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425712600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425709900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425707100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425704500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425701740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425699020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425696300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425693600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425690860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425688140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425685450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425682730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425679980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425677300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425674570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425671850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425669100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425666380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425663700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425660970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425658300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425655500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425652800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425650100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425647400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425644620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425641930000.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(425639180000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425636560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425633840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425631150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425628370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425625650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425622960000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425620200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425617500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425614800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425612100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425609400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425606640000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425603900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425601200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425598520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425595830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425593040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425590360000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425587640000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425584950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425582170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425579450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425576760000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425574070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425571300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425568570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425565900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425563130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425560440000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425557720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425555000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425552300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425549560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425546900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425544160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425541470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425538680000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425536060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425533340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425530650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425527870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425525180000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425522400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425519700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425517000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425514300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425511520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425508900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425506140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425503420000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425500740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425497950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425495270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425492480000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425489860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425487140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425484350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425481700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425478980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425476260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425473600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425470820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425468130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425465380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425462600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425459900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425457220000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425454530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425451800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425449060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425446380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425443720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425440940000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425438250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425435560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425432780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425430100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425427400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425424620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425421930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425419280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425416500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425413800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425411020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425408330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425405640000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425402960000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425400270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425397520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425394730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425392050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425389300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425386570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425383900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425381200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425378480000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425375730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425373000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425370300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425367600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425364900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425362200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425359440000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425356750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425354040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425351300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425348630000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425345880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425343160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425340470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425337850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425335100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425332300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425329660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425326970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425324200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425321500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425318700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425316000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425313200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425310520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425307870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425305150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425302520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425299840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425297050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425294330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425291580000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425288860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425286170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425283450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425280700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425278000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425275300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425272600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425269900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425267200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425264450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425261760000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425259000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425256260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425253570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425250850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425248160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425245470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425242700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425240000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425237200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425234560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425231800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425229100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425226400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425223720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425220930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425218240000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425215560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425212900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425210120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425207430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425204650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425201960000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425199270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425196500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425193800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425191150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425188460000.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(425185700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425183000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425180300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425177580000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425174830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425172140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425169420000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425166700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425164000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425161260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425158540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425155850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425153170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425150380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425147700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425145040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425142260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425139570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425136800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425134100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425131400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425128620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425125940000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425123280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425120600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425117900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425115120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425112440000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425109720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425106960000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425104280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425101560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425098840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425096100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425093370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425090680000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425088000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425085300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425082600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425079830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425077080000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425074400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425071700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425069020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425066330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425063600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425060860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425058170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425055400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425052730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425050050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425047360000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425044570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425041850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425039100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425036400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425033730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425030980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425028300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425025600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425022850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425020200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425017400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425014720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425012040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425009300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425006560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425003840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(425001100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424998370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424995750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424993000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424990200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424987660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424984900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424982200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424979500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424976700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424974020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424971300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424968650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424965870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424963200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424960460000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424957740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424955050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424952330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424949580000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424946900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424944170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424941450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424938700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424935980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424933300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424930600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424927920000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424925200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424922450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424919830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424917000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424914320000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424911540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424908880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424906160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424903540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424900760000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424898000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424895350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424892560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424889880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424887120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424884400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424881720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424879030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424876300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424873700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424871000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424868220000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424865530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424862740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424860120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424857370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424854700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424851900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424849240000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424846500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424843770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424841100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424838400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424835680000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424832930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424830240000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424827500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424824800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424822000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424819260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424816640000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424813950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424811230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424808480000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424805800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424803140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424800350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424797670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424794980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424792300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424789500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424786820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424784130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424781400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424778700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424776000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424773260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424770630000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424767850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424765160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424762470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424759720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424757040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424754280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424751560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424748880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424746200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424743400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424740700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424737930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424735300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424732600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424729900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424727150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424724500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424721740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424719020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424716340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424713620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424710930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424708150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424705460000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424702740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424700050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424697300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424694600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424691900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424689170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424686520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424683800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424681100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424678420000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424675600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424672850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424670170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424667400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424664730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424662140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424659350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424656570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424653880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424651200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424648500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424645850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424643070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424640380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424637700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424634970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424632220000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424629530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424626850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424624130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424621400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424618720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424616030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424613250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424610560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424607880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424605100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424602400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424599750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424597060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424594280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424591600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424588870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424586120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424583430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424580740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424578020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424575340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424572620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424569930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424567200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424564460000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424561770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424559050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424556360000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424553640000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424550900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424548200000.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(424545500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424542770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424540000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424537330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424534540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424531900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424529200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424526500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424523830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424521140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424518350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424515670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424512980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424510260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424507540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424504850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424502070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424499380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424496700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424494000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424491300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424488600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424485880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424483130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424480400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424477720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424475100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424472250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424469560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424466840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424464220000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424461430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424458750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424456060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424453280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424450600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424447900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424445200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424442500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424439780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424437100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424434340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424431600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424428900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424426200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424423520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424420800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424418050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424415330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424412640000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424410020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424407270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424404550000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424401800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424399100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424396400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424393670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424391000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424388300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424385500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424382820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424380040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424377420000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424374700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424372000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424369230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424366540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424363850000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424361160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424358380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424355700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424353040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424350350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424347570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424344880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424342130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424339470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424336820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424334030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424331350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424328700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424325900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424323250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424320530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424317800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424315060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424312370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424309700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424306970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424304280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424301560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424298870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424296200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424293470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424290700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424288030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424285270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424282600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424279900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424277200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424274430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424271740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424269050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424266330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424263650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424260860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424258240000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424255460000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424252770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424249980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424247300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424244600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424241900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424239270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424236580000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424233800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424231100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424228320000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424225700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424222950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424220260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424217600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424214820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424212230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424209380000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424206760000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424204040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424201300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424198500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424195950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424193160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424190500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424187720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424185070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424182300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424179630000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424176900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424174160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424171500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424168820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424166030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424163280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424160660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424157870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424155200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424152500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424149880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424147160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424144470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424141780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424139060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424136280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424133530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424130840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424128200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424125400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424122800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424120030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424117340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424114550000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424111870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424109180000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424106400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424103740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424101050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424098370000.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(424095680000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424092900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424090200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424087520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424084730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424082080000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424079400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424076700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424073950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424071230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424068550000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424065860000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424063170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424060420000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424057730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424055050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424052300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424049570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424046950000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424044100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424041480000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424038760000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424036070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424033320000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424030700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424027900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424025230000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424022540000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424019820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424017070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424014400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424011660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424009040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424006300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424003530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(424000880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423998100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423995400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423992750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423990000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423987300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423984600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423981880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423979200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423976440000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423973750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423971100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423968400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423965720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423962940000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423960250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423957530000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423954780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423952100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423949430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423946750000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423943960000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423941280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423938600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423935870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423933100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423930400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423927700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423925020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423922400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423919600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423916930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423914140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423911460000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423908770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423906000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423903330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423900580000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423897960000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423895270000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423892500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423889800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423887100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423884420000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423881670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423879000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423876300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423873600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423870900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423868200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423865450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423862670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423860040000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423857320000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423854640000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423851900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423849260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423846480000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423843800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423841100000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423838320000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423835660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423832980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423830200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423827500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423824820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423822130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423819440000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423816660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423814000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423811320000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423808630000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423805880000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423803260000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423800470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423797800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423795060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423792350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423789660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423786900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423784200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423781500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423778800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423776120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423773440000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423770800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423768030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423765250000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423762620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423759840000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423757150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423754470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423751780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423749060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423746340000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423743650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423740870000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423738200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423735500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423732770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423730120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423727330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423724680000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423722000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423719240000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423716520000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423713900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423711150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423708460000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423705740000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423703020000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423700330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423697650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423694960000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423692170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423689500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423686770000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423684080000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423681360000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423678670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423676000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423673300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423670500000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423667830000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423665140000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423662450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423659670000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423657000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423654330000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423651640000.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(423648900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423646170000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423643450000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423640800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423638070000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423635350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423632700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423629980000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423627300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423624570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423621820000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423619130000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423616400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423613730000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423610940000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423608220000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423605630000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423602900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423600160000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423597440000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423594700000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423592030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423589350000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423586660000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423583970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423581300000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423578570000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423575800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423573200000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423570400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423567720000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423565000000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423562400000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423559600000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423556900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423554150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423551470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423548680000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423546060000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423543370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423540650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423537970000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423535280000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423532560000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423529800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423527120000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423524470000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423521780000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423519030000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423516240000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423513620000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423510900000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423508150000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423505430000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423502800000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423500050000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423497370000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423494650000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423491930000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423489240000.0, shape=(), dtype=float32)\n",
      "tf.Tensor(423486600000.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for j in range(1000):\n",
    "    optimizer.minimize(lambda: loss_function(intercept, slope), var_list = [intercept, slope])\n",
    "    print(loss_function(intercept, slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.099176 1.0991883\n"
     ]
    }
   ],
   "source": [
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(intercept, slope):\n",
    "        size_range = np.linspace(6,14,100)\n",
    "        price_pred = [intercept+slope*s for s in size_range]\n",
    "        plt.scatter(size, price, color = 'black')\n",
    "        plt.plot(size_range, price_pred, linewidth=3.0, color='red')\n",
    "        plt.xlabel('log(size)')\n",
    "        plt.ylabel('log(price)')\n",
    "        plt.title('Scatterplot of data and fitted regression line')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(intercept, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in pd.read_csv(\"kc_house_data.csv\", chunksize = 100):\n",
    "    price = np.array(batch[\"price\"], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1537000.,  467000.,  224000.,  507250.,  429000.,  610685.,\n",
       "       1007500.,  475000.,  360000.,  400000.,  402101.,  400000.,\n",
       "        325000.], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the intercept and slope\n",
    "intercept = tf.Variable(10.0, tf.float32)\n",
    "slope = tf.Variable(0.5, tf.float32)\n",
    "\n",
    "# Define the model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    # Define the predicted values\n",
    "    return intercept + slope * features\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    # Define the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    "    # Define the MSE loss\n",
    "    return keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.217888 0.7016001\n"
     ]
    }
   ],
   "source": [
    "# Initialize adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
    "    size_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "\n",
    "    # Extract the price values for the current batch\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "\n",
    "    # Complete the loss, fill in the variable list, and minimize\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
    "\n",
    "# Print trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.constant([[1.0, 35.0]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable([[-0.05],[-0.01]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = tf.Variable([0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = tf.matmul(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.activations.sigmoid(product + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bias1\n",
    "bias1 = tf.Variable(1.0)\n",
    "\n",
    "# Initialize weights1 as 3x2 variable of ones\n",
    "weights1 = tf.Variable(tf.ones((3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrower_features = tf.cast([[ 2.,  2., 43.]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform matrix multiplication of borrower_features and weights1\n",
    "product1 = tf.matmul(borrower_features, weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dense1's output shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Apply sigmoid activation function to product1 + bias1\n",
    "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Print shape of dense1\n",
    "print(\"\\n dense1's output shape: {}\".format(dense1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " prediction: 0.9525741338729858\n",
      "\n",
      " actual: 1\n"
     ]
    }
   ],
   "source": [
    "# From previous step\n",
    "bias1 = tf.Variable(1.0)\n",
    "weights1 = tf.Variable(tf.ones((3, 2)))\n",
    "product1 = tf.matmul(borrower_features, weights1)\n",
    "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Initialize bias2 and weights2\n",
    "bias2 = tf.Variable(1.0)\n",
    "weights2 = tf.Variable(tf.ones((2, 1)))\n",
    "\n",
    "# Perform matrix multiplication of dense1 and weights2\n",
    "product2 = tf.matmul(dense1, weights2)\n",
    "\n",
    "# Apply activation to product2 + bias2 and print the prediction\n",
    "prediction = keras.activations.sigmoid(product2 + bias2)\n",
    "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
    "print('\\n actual: 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = tf.cast(np.array([[-0.6 ,  0.6],[ 0.8 , -0.3],[-0.09, -0.08]]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias1 = tf.cast(np.array([0.1]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrower_featues = tf.cast(np.array([[ 3.,  3., 23.],[ 2.,  1., 24.],[ 1.,  1., 49.],[ 1.,  1., 49.],[ 2.,  1., 29.]]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " shape of borrower_features:  (5, 3)\n",
      "\n",
      " shape of weights1:  (3, 2)\n",
      "\n",
      " shape of bias1:  (1,)\n",
      "\n",
      " shape of dense1:  (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Compute the product of borrower_features and weights1\n",
    "products1 = tf.matmul(borrower_features, weights1)\n",
    "\n",
    "# Apply a sigmoid activation function to products1 + bias1\n",
    "dense1 = keras.activations.sigmoid(products1 + bias1)\n",
    "\n",
    "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
    "print('\\n shape of borrower_features: ', borrower_featues.shape)\n",
    "print('\\n shape of weights1: ', weights1.shape)\n",
    "print('\\n shape of bias1: ', bias1.shape)\n",
    "print('\\n shape of dense1: ', dense1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0332463 , 0.06065392]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.4700003, -2.8399997]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " shape of dense1:  (1, 7)\n",
      "\n",
      " shape of dense2:  (1, 3)\n",
      "\n",
      " shape of predictions:  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define the first dense layer\n",
    "dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "# Define a dense layer with 3 output nodes\n",
    "dense2 = keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
    "\n",
    "# Define a dense layer with 1 output node\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print the shapes of dense1, dense2, and predictions\n",
    "print('\\n shape of dense1: ', dense1.shape)\n",
    "print('\\n shape of dense2: ', dense2.shape)\n",
    "print('\\n shape of predictions: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct input layer from features\n",
    "inputs = keras.layers.Input()\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = keras.layers.Dense(16, activation='relu')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = keras.layers.Dense(8, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = keras.layers.Dense(2, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print error for first five examples\n",
    "error = default[:5] - outputs.numpy()[:5]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data = pd.read_csv(\"uci_credit_card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2682.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>188948.0</td>\n",
       "      <td>192815.0</td>\n",
       "      <td>208365.0</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>1683.0</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>3565.0</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>-1645.0</td>\n",
       "      <td>78379.0</td>\n",
       "      <td>76304.0</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>47929.0</td>\n",
       "      <td>48905.0</td>\n",
       "      <td>49764.0</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6\n",
       "0         3913.0     3102.0      689.0        0.0        0.0        0.0\n",
       "1         2682.0     1725.0     2682.0     3272.0     3455.0     3261.0\n",
       "2        29239.0    14027.0    13559.0    14331.0    14948.0    15549.0\n",
       "3        46990.0    48233.0    49291.0    28314.0    28959.0    29547.0\n",
       "4         8617.0     5670.0    35835.0    20940.0    19146.0    19131.0\n",
       "...          ...        ...        ...        ...        ...        ...\n",
       "29995   188948.0   192815.0   208365.0    88004.0    31237.0    15980.0\n",
       "29996     1683.0     1828.0     3502.0     8979.0     5190.0        0.0\n",
       "29997     3565.0     3356.0     2758.0    20878.0    20582.0    19357.0\n",
       "29998    -1645.0    78379.0    76304.0    52774.0    11855.0    48944.0\n",
       "29999    47929.0    48905.0    49764.0    36535.0    32428.0    15313.0\n",
       "\n",
       "[30000 rows x 6 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data[[\"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3913.,  3102.,   689.,     0.,     0.,     0.],\n",
       "       [ 2682.,  1725.,  2682.,  3272.,  3455.,  3261.],\n",
       "       [29239., 14027., 13559., 14331., 14948., 15549.],\n",
       "       ...,\n",
       "       [ 3565.,  3356.,  2758., 20878., 20582., 19357.],\n",
       "       [-1645., 78379., 76304., 52774., 11855., 48944.],\n",
       "       [47929., 48905., 49764., 36535., 32428., 15313.]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cc_data[[\"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\"]], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_amount = np.array(cc_data[[\"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\"]], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = np.array(cc_data[\"default.payment.next.month\"], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bill_amount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. -1. -1. -1.]\n",
      " [ 0.  0. -1. -1. -1.]\n",
      " [ 0.  0. -1. -1. -1.]\n",
      " [ 0.  0. -1. -1. -1.]\n",
      " [ 0.  0. -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "# Construct input layer from features\n",
    "inputs = tf.constant(bill_amount, tf.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = keras.layers.Dense(3, activation='relu')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print error for first five examples\n",
    "error = default[:5] - outputs.numpy()[:5]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19619724 0.12194616 0.1800152  0.10975666 0.22283009 0.1692547 ]\n",
      " [0.14923815 0.14624973 0.16514073 0.1375382  0.22956817 0.17226502]\n",
      " [0.14923815 0.14624973 0.16514073 0.1375382  0.22956817 0.17226502]\n",
      " [0.19619724 0.12194616 0.1800152  0.10975666 0.22283009 0.1692547 ]\n",
      " [0.07606713 0.10268036 0.31739843 0.115016   0.29474622 0.09409196]]\n"
     ]
    }
   ],
   "source": [
    "# Construct input layer from borrower features\n",
    "inputs = tf.constant(bill_amount, tf.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = keras.layers.Dense(8, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = keras.layers.Dense(6, activation='softmax')(dense2)\n",
    "\n",
    "# Print first five predictions\n",
    "print(outputs.numpy()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(bias, weights, features = bill_amount):\n",
    "    product = tf.matmul(features, weights)\n",
    "    return tf.keras.activations.sigmoid(product + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(bias, weights, targets = default, features = bill_amount):\n",
    "    predictions = model(bias,weights)\n",
    "    return keras.losses.binary_crossentropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(learning_rate = 0.001, momentum = 0.9)\n",
    "opt.minimize(lambda: loss_function(bias, weights), var_list = [bias, weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x):\n",
    "        return 4.0*math.cos(x-1)+divide(math.cos(2.0*pi*x),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 3.141592653589793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.027515 0.25\n"
     ]
    }
   ],
   "source": [
    "# Initialize x_1 and x_2\n",
    "x_1 = tf.Variable(6.0,tf.float32)\n",
    "x_2 = tf.Variable(0.3,tf.float32)\n",
    "\n",
    "# Define the optimization operation\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "for j in range(100):\n",
    "    # Perform minimization using the loss function and x_1\n",
    "    opt.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "    # Perform minimization using the loss function and x_2\n",
    "    opt.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7445114 0.24999999\n"
     ]
    }
   ],
   "source": [
    "# Initialize x_1 and x_2\n",
    "x_1 = tf.Variable(0.05,tf.float32)\n",
    "x_2 = tf.Variable(0.05,tf.float32)\n",
    "\n",
    "# Define the optimization operation for opt_1 and opt_2\n",
    "opt_1 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.99)\n",
    "opt_2 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.00)\n",
    "\n",
    "for j in range(100):\n",
    "    opt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "    # Define the minimization operation for opt_2\n",
    "    opt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layer 1 weights\n",
    "w1 = tf.Variable(np.random.normal([23, 7]))\n",
    "\n",
    "# Initialize the layer 1 bias\n",
    "b1 = tf.Variable(tf.ones([7]))\n",
    "\n",
    "# Define the layer 2 weights\n",
    "w2 = tf.Variable(np.random.normal([7, 1]))\n",
    "\n",
    "# Define the layer 2 bias\n",
    "b2 = tf.Variable(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = borrower_features):\n",
    "    # Apply relu activation functions to layer 1\n",
    "    layer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
    "    # Apply dropout\n",
    "    dropout = keras.layers.Dropout(0.25)(layer1)\n",
    "    return keras.activations.sigmoid(matmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
    "    predictions = model(w1, b1, w2, b2)\n",
    "    # Pass targets and predictions to the cross entropy loss\n",
    "    return keras.losses.binary_crossentropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(16, activation = \"relu\", input_shape = (28*28,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(8, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(4, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 12,732\n",
      "Trainable params: 12,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 12,732\n",
      "Trainable params: 12,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a Keras sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the second dense layer\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation = \"softmax\"))\n",
    "\n",
    "# Print the model architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 12,880\n",
      "Trainable params: 12,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation = \"sigmoid\", input_shape = (784,)))\n",
    "\n",
    "# Apply dropout to the first layer's output\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation = \"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
    "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "# Merge model outputs and define a functional model\n",
    "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
    "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_data = pd.read_csv(\"slmnist.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>147</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>198</td>\n",
       "      <td>193</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>164</td>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0    1  142  143  146  148  149  149  149  150  151  ...    0   15   55   63   \n",
       "1    0  141  142  144  145  147  149  150  151  152  ...  173  179  179  180   \n",
       "2    1  156  157  160  162  164  166  169  171  171  ...  181  197  195  193   \n",
       "3    3   63   26   65   86   97  106  117  123  128  ...  175  179  180  182   \n",
       "4    1  156  160  164  168  172  175  178  180  182  ...  108  107  106  110   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0   37   61   77   65   38   23  \n",
       "1  181  181  182  182  183  183  \n",
       "2  193  191  192  198  193  182  \n",
       "3  183  183  184  185  185  185  \n",
       "4  111  108  108  102   84   70  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_labels = sign_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    3\n",
       "4    1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_language_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_features = sign_data[sign_data.columns.difference([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>147</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>198</td>\n",
       "      <td>193</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>164</td>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1    2    3    4    5    6    7    8    9    10   ...  775  776  777  778  \\\n",
       "0  142  143  146  148  149  149  149  150  151  151  ...    0   15   55   63   \n",
       "1  141  142  144  145  147  149  150  151  152  154  ...  173  179  179  180   \n",
       "2  156  157  160  162  164  166  169  171  171  171  ...  181  197  195  193   \n",
       "3   63   26   65   86   97  106  117  123  128  132  ...  175  179  180  182   \n",
       "4  156  160  164  168  172  175  178  180  182  183  ...  108  107  106  110   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0   37   61   77   65   38   23  \n",
       "1  181  181  182  182  183  183  \n",
       "2  193  191  192  198  193  182  \n",
       "3  183  183  184  185  185  185  \n",
       "4  111  108  108  102   84   70  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_language_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_features = sign_language_features.astype(np.float64) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.090196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.717647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.713725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.725490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.274510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         2         3         4         5         6         7    \\\n",
       "0  0.556863  0.560784  0.572549  0.580392  0.584314  0.584314  0.584314   \n",
       "1  0.552941  0.556863  0.564706  0.568627  0.576471  0.584314  0.588235   \n",
       "2  0.611765  0.615686  0.627451  0.635294  0.643137  0.650980  0.662745   \n",
       "3  0.247059  0.101961  0.254902  0.337255  0.380392  0.415686  0.458824   \n",
       "4  0.611765  0.627451  0.643137  0.658824  0.674510  0.686275  0.698039   \n",
       "\n",
       "        8         9         10   ...       775       776       777       778  \\\n",
       "0  0.588235  0.592157  0.592157  ...  0.000000  0.058824  0.215686  0.247059   \n",
       "1  0.592157  0.596078  0.603922  ...  0.678431  0.701961  0.701961  0.705882   \n",
       "2  0.670588  0.670588  0.670588  ...  0.709804  0.772549  0.764706  0.756863   \n",
       "3  0.482353  0.501961  0.517647  ...  0.686275  0.701961  0.705882  0.713725   \n",
       "4  0.705882  0.713725  0.717647  ...  0.423529  0.419608  0.415686  0.431373   \n",
       "\n",
       "        779       780       781       782       783       784  \n",
       "0  0.145098  0.239216  0.301961  0.254902  0.149020  0.090196  \n",
       "1  0.709804  0.709804  0.713725  0.713725  0.717647  0.717647  \n",
       "2  0.756863  0.749020  0.752941  0.776471  0.756863  0.713725  \n",
       "3  0.717647  0.717647  0.721569  0.725490  0.725490  0.725490  \n",
       "4  0.435294  0.423529  0.423529  0.400000  0.329412  0.274510  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_language_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_labels_onehot = tf.one_hot(sign_language_labels, depth = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_language_labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_labels_onehot = tf.cast(sign_language_labels_onehot, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_features = tf.cast(sign_language_features, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_language_labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 784), dtype=float32, numpy=\n",
       "array([[0.5568628 , 0.56078434, 0.57254905, ..., 0.25490198, 0.14901961,\n",
       "        0.09019608],\n",
       "       [0.5529412 , 0.5568628 , 0.5647059 , ..., 0.7137255 , 0.7176471 ,\n",
       "        0.7176471 ],\n",
       "       [0.6117647 , 0.6156863 , 0.627451  , ..., 0.7764706 , 0.75686276,\n",
       "        0.7137255 ],\n",
       "       ...,\n",
       "       [0.69411767, 0.7019608 , 0.7058824 , ..., 0.9372549 , 0.9137255 ,\n",
       "        0.9411765 ],\n",
       "       [0.4745098 , 0.5058824 , 0.5411765 , ..., 0.77254903, 0.7764706 ,\n",
       "        0.827451  ],\n",
       "       [0.69803923, 0.69803923, 0.69803923, ..., 0.7647059 , 0.7607843 ,\n",
       "        0.7529412 ]], dtype=float32)>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_language_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 815us/step - loss: 1.3222\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 812us/step - loss: 1.0405\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 875us/step - loss: 0.8152\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 778us/step - loss: 0.6637\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 882us/step - loss: 0.5666\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 872us/step - loss: 0.4994\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 809us/step - loss: 0.4455\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 815us/step - loss: 0.4032\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 775us/step - loss: 0.3636\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 776us/step - loss: 0.3269\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 773us/step - loss: 0.2923\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 780us/step - loss: 0.2597\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.2334\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.2079\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 851us/step - loss: 0.1849\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 924us/step - loss: 0.1668\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 875us/step - loss: 0.1528\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 988us/step - loss: 0.1362\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 816us/step - loss: 0.1236\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 760us/step - loss: 0.1124\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 809us/step - loss: 0.1029\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 834us/step - loss: 0.0964\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 780us/step - loss: 0.0874\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 793us/step - loss: 0.0807\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 794us/step - loss: 0.0740\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0702\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 787us/step - loss: 0.0652\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.0610\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 746us/step - loss: 0.0578\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 813us/step - loss: 0.0543\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 866us/step - loss: 0.0511\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 759us/step - loss: 0.0487\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 809us/step - loss: 0.0454\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 780us/step - loss: 0.0432\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 794us/step - loss: 0.0416\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 826us/step - loss: 0.0400\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 859us/step - loss: 0.0375\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 785us/step - loss: 0.0355\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 748us/step - loss: 0.0342\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 779us/step - loss: 0.0325\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.0320\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 789us/step - loss: 0.0306\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 779us/step - loss: 0.0293\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 814us/step - loss: 0.0280\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 772us/step - loss: 0.0269\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 741us/step - loss: 0.0261\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 788us/step - loss: 0.0251\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0244\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 764us/step - loss: 0.0235\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 817us/step - loss: 0.0226\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 929us/step - loss: 0.0219\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 805us/step - loss: 0.0213\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 812us/step - loss: 0.0208\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 921us/step - loss: 0.0203\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 871us/step - loss: 0.0195\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 751us/step - loss: 0.0191\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 762us/step - loss: 0.0185\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 777us/step - loss: 0.0179\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0177\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 825us/step - loss: 0.0172\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 764us/step - loss: 0.0166\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 787us/step - loss: 0.0162\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.0157\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 781us/step - loss: 0.0153\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.0150\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 813us/step - loss: 0.0148\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 752us/step - loss: 0.0144\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 706us/step - loss: 0.0141\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 700us/step - loss: 0.0136\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 745us/step - loss: 0.0135\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 755us/step - loss: 0.0132\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 779us/step - loss: 0.0128\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 732us/step - loss: 0.0127\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 746us/step - loss: 0.0124\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 757us/step - loss: 0.0123\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 755us/step - loss: 0.0119\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 819us/step - loss: 0.0117\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 751us/step - loss: 0.0115\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 746us/step - loss: 0.0111\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 725us/step - loss: 0.0110\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 871us/step - loss: 0.0108\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 759us/step - loss: 0.0107\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 779us/step - loss: 0.0104\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 765us/step - loss: 0.0103\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 841us/step - loss: 0.0101\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 734us/step - loss: 0.0099\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 788us/step - loss: 0.0096\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 783us/step - loss: 0.0096\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 809us/step - loss: 0.0094\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 848us/step - loss: 0.0093\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 789us/step - loss: 0.0092\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 822us/step - loss: 0.0090\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 725us/step - loss: 0.0089\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 734us/step - loss: 0.0087\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 695us/step - loss: 0.0086\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 720us/step - loss: 0.0085\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.0084\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 738us/step - loss: 0.0082\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 745us/step - loss: 0.0081\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 776us/step - loss: 0.0080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f4c5255d0>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define a hidden layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation = \"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('SGD', loss='categorical_crossentropy')\n",
    "\n",
    "# Complete the fitting operation\n",
    "model.fit(sign_language_features, sign_language_labels_onehot, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1362 - accuracy: 0.5578 - val_loss: 1.0676 - val_accuracy: 0.4600\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7995 - accuracy: 0.8000 - val_loss: 0.8249 - val_accuracy: 0.7300\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.8700 - val_loss: 0.5706 - val_accuracy: 0.8600\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.9122 - val_loss: 0.5038 - val_accuracy: 0.7600\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.9444 - val_loss: 0.3781 - val_accuracy: 0.8400\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.9506 - val_loss: 0.2649 - val_accuracy: 0.9650\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9689 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9700 - val_loss: 0.1863 - val_accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9839 - val_loss: 0.1419 - val_accuracy: 0.9850\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9833 - val_loss: 0.1998 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f4c45ec10>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model.add(keras.layers.Dense(32, activation = \"sigmoid\", input_shape = (784,)))\n",
    "\n",
    "# Add activation function to classifier\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Set the optimizer, loss function, and metrics\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add the number of epochs and the validation split\n",
    "model.fit(sign_language_features, sign_language_labels_onehot, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0580 - accuracy: 0.6050 - val_loss: 0.5830 - val_accuracy: 0.7490\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8810 - val_loss: 0.2953 - val_accuracy: 0.8920\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2281 - accuracy: 0.9760 - val_loss: 0.3124 - val_accuracy: 0.8390\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1798 - accuracy: 0.9640 - val_loss: 0.1461 - val_accuracy: 0.9680\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1325 - accuracy: 0.9720 - val_loss: 0.1804 - val_accuracy: 0.9650\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9890 - val_loss: 0.1035 - val_accuracy: 0.9830\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9960 - val_loss: 0.0725 - val_accuracy: 0.9810\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9940 - val_loss: 0.1107 - val_accuracy: 0.9710\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9950 - val_loss: 0.0656 - val_accuracy: 0.9860\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9960 - val_loss: 0.0574 - val_accuracy: 0.9860\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9970 - val_loss: 0.0468 - val_accuracy: 0.9880\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.0322 - val_accuracy: 0.9910\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.9990 - val_loss: 0.0492 - val_accuracy: 0.9860\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9990 - val_loss: 0.0243 - val_accuracy: 0.9910\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9990 - val_loss: 0.0228 - val_accuracy: 0.9910\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9920\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9960\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9960\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9980\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9940\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9940\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9920\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9970\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9920\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9920\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9990\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9970\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9950\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9920\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9930\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.0078 - val_accuracy: 0.9990\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9970\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6901e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.4236e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.7397e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.6745e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f4c1ac910>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model.add(keras.layers.Dense(1024, activation='relu', input_shape = (784,)))\n",
    "\n",
    "# Add activation function to classifier\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Complete the model fit operation\n",
    "model.fit(sign_language_features, sign_language_labels_onehot, epochs=50, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the validation loss, val_loss, was substantially higher than the training loss, loss. Furthermore, if val_loss started to increase before the training process was terminated, then we may have overfitted. When this happens, you will want to try decreasing the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "\n",
      " Model - Train: [0.0020089601166546345, 1.0]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation = model.evaluate(sign_language_features, sign_language_labels_onehot)\n",
    "\n",
    "# Print losses\n",
    "print('\\n Model - Train: {}'.format(model_evaluation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:virtenv] *",
   "language": "python",
   "name": "conda-env-virtenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
